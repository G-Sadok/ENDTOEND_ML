{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a935ba93433232",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f53ea8c829a87d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:52:34.163567Z",
     "start_time": "2025-11-21T08:52:32.064479Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib, os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a29b49f2b18f2c",
   "metadata": {},
   "source": [
    "## Recup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c370c4bbacd578e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:52:41.176561Z",
     "start_time": "2025-11-21T08:52:40.560263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset chargé — premières lignes :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>test</td>\n",
       "      <td>Tyra Banks needs to teach these girls that it'...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10086_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>test</td>\n",
       "      <td>This is by far the most vapid, idiotic, insane...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10087_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>test</td>\n",
       "      <td>It was awful plain and simple. What was their ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10088_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>test</td>\n",
       "      <td>Wow! i think they made this movie to torture p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10089_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>test</td>\n",
       "      <td>This movie could very well have been a propaga...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1008_2.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  type                                             review label  \\\n",
       "0            0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1            1  test  This is an example of why the majority of acti...   neg   \n",
       "2            2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3            3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4            4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "..         ...   ...                                                ...   ...   \n",
       "95          95  test  Tyra Banks needs to teach these girls that it'...   neg   \n",
       "96          96  test  This is by far the most vapid, idiotic, insane...   neg   \n",
       "97          97  test  It was awful plain and simple. What was their ...   neg   \n",
       "98          98  test  Wow! i think they made this movie to torture p...   neg   \n",
       "99          99  test  This movie could very well have been a propaga...   neg   \n",
       "\n",
       "           file  \n",
       "0       0_2.txt  \n",
       "1   10000_4.txt  \n",
       "2   10001_1.txt  \n",
       "3   10002_3.txt  \n",
       "4   10003_3.txt  \n",
       "..          ...  \n",
       "95  10086_1.txt  \n",
       "96  10087_1.txt  \n",
       "97  10088_1.txt  \n",
       "98  10089_1.txt  \n",
       "99   1008_2.txt  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Colonnes : ['Unnamed: 0', 'type', 'review', 'label', 'file']\n",
      "Nombre de lignes : 100000\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(\"imdb.csv\", encoding='latin-1')\n",
    "print(\"Dataset chargé — premières lignes :\")\n",
    "display(all_data.head(100))\n",
    "print(\"\\nColonnes :\", all_data.columns.tolist())\n",
    "print(\"Nombre de lignes :\", len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6276b8e8df2250f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:56:29.129624Z",
     "start_time": "2025-11-21T08:56:29.076680Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = all_data.dropna()\n",
    "all_data = all_data.loc[all_data['label'] != 'unsup']\n",
    "all_data = all_data.drop_duplicates(subset='review', keep='last')\n",
    "# all_data = all_data.drop(all_data['label'] == 'unsup')\n",
    "X = all_data['review']\n",
    "y = all_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "y_train = column_or_1d(y_train, warn=False)\n",
    "y_test = column_or_1d(y_test, warn=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d44a9ba3d05bdf1",
   "metadata": {},
   "source": [
    "## Fonctions de Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25479a4af7f2856e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:52:59.469214Z",
     "start_time": "2025-11-21T08:52:59.464474Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_stopwords():\n",
    "    filepath = \"My_stopwords.txt\"\n",
    "    all_stopwords = set(stopwords.words('english'))\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_data = f.read()\n",
    "        data_fetch = raw_data.split(\",\")\n",
    "        mine_stopwords = [word.strip().strip('\"').strip(\"'\").lower() for word in data_fetch if word.strip()]\n",
    "        all_stopwords.update(mine_stopwords)\n",
    "        return all_stopwords\n",
    "    except FileNotFoundError:\n",
    "        print(\"Le fichier My_stopwords.txt est introuvable. Les stopwords par défaut seront utilisés.\")\n",
    "        return all_stopwords\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur est survenue : {e}\")\n",
    "        return all_stopwords\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def preprocessing(line):\n",
    "    tokens = []\n",
    "    tokens.extend(word_tokenize(line))\n",
    "    all_stopwords = fetch_stopwords()\n",
    "    W_tempor = [w for w in tokens if w.isalpha() and len(w) > 1]\n",
    "    clean_tokens = [w.lower() for w in W_tempor if w.lower() not in all_stopwords]\n",
    "\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in clean_tokens]\n",
    "\n",
    "    lemmatized_words = [w for w in lemmatized_words if w not in all_stopwords]\n",
    "\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ea3de14e2ef57",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b22da9f5ec0bece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:57:54.895998Z",
     "start_time": "2025-11-21T08:56:32.824855Z"
    }
   },
   "outputs": [],
   "source": [
    "cpt = 0\n",
    "\n",
    "for line in X_train:\n",
    "    X_train[cpt] = preprocessing(line)\n",
    "    cpt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "915ae7aaaa81153d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:58:29.355521Z",
     "start_time": "2025-11-21T08:57:54.904258Z"
    }
   },
   "outputs": [],
   "source": [
    "cpt1 = 0\n",
    "\n",
    "for line in X_test:\n",
    "    X_test[cpt1] = preprocessing(line)\n",
    "    cpt1 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50944e9a632c5c61",
   "metadata": {},
   "source": [
    "## Test des models disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d63b39accf9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "# X_train_vec = vectorizer.fit_transform(X_train)\n",
    "# X_test_vec  = vectorizer.transform(X_test)\n",
    "#\n",
    "# models = {\n",
    "#     \"RandomForest\": RandomForestClassifier(),\n",
    "#     \"SVM\": SVC(),\n",
    "#     \"KNN\": KNeighborsClassifier(),\n",
    "#     \"MLP\": MLPClassifier(),\n",
    "# }\n",
    "#\n",
    "# results = {}\n",
    "#\n",
    "# for name, model in models.items():\n",
    "#     pipe = Pipeline([\n",
    "#         (\"model\", model)\n",
    "#     ])\n",
    "#\n",
    "#     pipe.fit(X_train_vec, y_train)\n",
    "#     y_pred = pipe.predict(X_test_vec)\n",
    "#     results[name] = accuracy_score(y_test, y_pred)\n",
    "#\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a15a50b6302f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train[y_train==\"neg\"] = 0\n",
    "# y_train[y_train==\"pos\"] = 1\n",
    "#\n",
    "# y_test[y_test==\"neg\"] = 0\n",
    "# y_test[y_test==\"pos\"] = 1\n",
    "#\n",
    "# y_train = y_train.astype(int)\n",
    "# y_test = y_test.astype(int)\n",
    "#\n",
    "# model = Pipeline([\n",
    "#     (\"tfidf\", TfidfVectorizer()),\n",
    "#     (\"clf\", LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "#\n",
    "#\n",
    "# print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "# print(\"\\nClassification report :\")\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad120a7da2b5462",
   "metadata": {},
   "source": [
    "## Entraînement du Model Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042744a2291196a",
   "metadata": {},
   "source": [
    "{'RandomForest': 0.8520336134453782, 'SVM': 0.8989579831932774, 'KNN': 0.7719663865546218, 'MLP': 0.8783193277310924, 'LogisticRegression' : 0.890890756302521}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d00ef21f62aa4b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:58:29.462873Z",
     "start_time": "2025-11-21T08:58:29.364971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        lead actress strikingly beautiful plot stand c...\n",
       "1        view movie time nuance perception life ordinar...\n",
       "2        otaku day robotech gunbuster favorite anime ti...\n",
       "3        today thought people include heaven gate maste...\n",
       "4        basic idea movie good real character developme...\n",
       "                               ...                        \n",
       "14870    rks success ghayal start film comedy film year...\n",
       "14871    boring film main cast member click giovanni ri...\n",
       "14872    kate beckinsale good gwyneth paltrow emma movi...\n",
       "14873    angst imdb reviewer hate film masterpiece view...\n",
       "14874    start watch year friend time young enjoy joke ...\n",
       "Name: review, Length: 14875, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.apply(lambda mots: \" \".join(mots))\n",
    "X_test = X_test.apply(lambda mots: \" \".join(mots))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c182a5ed4d792e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T09:19:13.188761Z",
     "start_time": "2025-11-21T09:05:15.791856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'entraînement... (peut prendre quelques minutes)\n",
      "Entraînement terminé.\n",
      "Accuracy : 0.8829579831932773\n",
      "\n",
      "Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.90      0.87      0.88      7500\n",
      "         pos       0.87      0.90      0.88      7375\n",
      "\n",
      "    accuracy                           0.88     14875\n",
      "   macro avg       0.88      0.88      0.88     14875\n",
      "weighted avg       0.88      0.88      0.88     14875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"svc\", SVC())\n",
    "])\n",
    "\n",
    "print(\"Début de l'entraînement... (peut prendre quelques minutes)\")\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Entraînement terminé.\")\n",
    "\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification report :\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfb866f9b94313",
   "metadata": {},
   "source": [
    "## Enregistrement du Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c24e32667de8ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T09:21:13.325207Z",
     "start_time": "2025-11-21T09:21:13.202342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé dans: model_final.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_path = \"model_final.pkl\"\n",
    "\n",
    "pickle.dump(pipe, open(\"model_final.pkl\",\"wb\"))\n",
    "print(f\"Modèle sauvegardé dans: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7967b46108aca68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
